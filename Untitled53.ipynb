{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700015bc-84ec-48dc-a141-92d220fc6f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Model: Pipeline\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    get_ipython\n",
    "    %pip -q install pandas numpy scikit-learn vaderSentiment joblib\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# %% 1) Imports & paths\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Set your artifacts/output folder\n",
    "OUT_DIR = Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Review Sentiment Analyzer\")\n",
    "\n",
    "# Try to find a trained model saved by your pipelines\n",
    "MODEL_PATHS = [\n",
    "    OUT_DIR / \"model_tfidf_lr.joblib\",   # from the full pipeline script\n",
    "    OUT_DIR / \"model_sentiment.pkl\",     # from the build-artifacts script\n",
    "]\n",
    "\n",
    "def _load_model():\n",
    "    for mp in MODEL_PATHS:\n",
    "        if mp.exists():\n",
    "            return joblib.load(mp)\n",
    "    return None\n",
    "\n",
    "# Fallback sentiment (no model)\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "_vs = SentimentIntensityAnalyzer()\n",
    "\n",
    "def _rule_score(text: str) -> float:\n",
    "    return float(_vs.polarity_scores(text).get(\"compound\", 0.0))\n",
    "\n",
    "def _score_to_label(score: float, pos: float=0.2, neg: float=-0.2) -> str:\n",
    "    return \"positive\" if score >= pos else (\"negative\" if score <= neg else \"neutral\")\n",
    "\n",
    "MODEL = _load_model()\n",
    "print(\"Model:\", type(MODEL).__name__ if MODEL else \"None (will use VADER fallback)\")\n",
    "\n",
    "# %% 2) Predict helpers (single, many, from file)\n",
    "from typing import List\n",
    "\n",
    "def predict_one(text: str) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Returns (label, confidence/score).\n",
    "    - If a trained model is available: label from the model, confidence = max proba.\n",
    "    - Else: VADER fallback, confidence = |compound| score.\n",
    "    \"\"\"\n",
    "    t = (text or \"\").strip()\n",
    "    if not t:\n",
    "        return \"\", 0.0\n",
    "    if MODEL is not None:\n",
    "        lab = MODEL.predict([t])[0]\n",
    "        try:\n",
    "            proba = MODEL.predict_proba([t])\n",
    "            conf = float(np.max(proba))\n",
    "        except Exception:\n",
    "            conf = 0.0\n",
    "        return str(lab), conf\n",
    "    # Fallback\n",
    "    comp = _rule_score(t)\n",
    "    return _score_to_label(comp), float(abs(comp))\n",
    "\n",
    "def predict_many(texts: Iterable[str]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for t in texts:\n",
    "        lab, conf = predict_one(t)\n",
    "        rows.append({\"text\": t, \"sentiment\": lab, \"confidence\": conf})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def predict_from_file(input_path: Path,\n",
    "                      text_col: str = \"reviewText\",\n",
    "                      out_csv: Optional[Path] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads CSV/JSON, predicts sentiment for each row, writes predictions CSV.\n",
    "    Keeps original columns and appends ['sentiment', 'confidence'].\n",
    "    \"\"\"\n",
    "    if not input_path.exists():\n",
    "        raise FileNotFoundError(input_path)\n",
    "    if input_path.suffix.lower() == \".json\":\n",
    "        df_in = pd.read_json(input_path, lines=True)\n",
    "    else:\n",
    "        df_in = pd.read_csv(input_path)\n",
    "\n",
    "    # Auto-fallback if text_col not present\n",
    "    if text_col not in df_in.columns:\n",
    "        for cand in [\"Text\", \"text\", \"review\", \"content\", \"reviewText\"]:\n",
    "            if cand in df_in.columns:\n",
    "                text_col = cand\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Text column '{text_col}' not found. Available: {df_in.columns.tolist()}\"\n",
    "            )\n",
    "\n",
    "    preds = predict_many(df_in[text_col].astype(str).fillna(\"\").tolist())\n",
    "    out = pd.concat([df_in.reset_index(drop=True), preds[[\"sentiment\", \"confidence\"]]], axis=1)\n",
    "    if out_csv is None:\n",
    "        out_csv = OUT_DIR / \"predictions.csv\"\n",
    "    out.to_csv(out_csv, index=False)\n",
    "    print(f\"[OK] Wrote predictions → {out_csv}\")\n",
    "    return out\n",
    "\n",
    "# %% 3) Quick ad-hoc test (edit the list and run)\n",
    "TEST_REVIEWS = [\n",
    "    \"The camera quality is amazing but the battery dies too fast.\",\n",
    "    \"Worst purchase ever. Completely stopped working in a week.\",\n",
    "    \"Packaging was okay. Works as expected.\",\n",
    "    \"Love the sound quality and the build! Totally worth it.\",\n",
    "]\n",
    "res_df = predict_many(TEST_REVIEWS)\n",
    "res_df\n",
    "\n",
    "# %% 4) Predict from your file (CSV/JSON) and save results\n",
    "# Point to your dataset; set the correct text column name (e.g., 'Text' or 'reviewText').\n",
    "IN_FILE = Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Review Sentiment Analyzer\\archive\\Reviews.csv\")\n",
    "TEXT_COL = \"Text\"   # change to 'reviewText' if that's your column\n",
    "OUT_FILE = OUT_DIR / \"predictions_from_reviews.csv\"\n",
    "\n",
    "# Uncomment to run:\n",
    "# file_out = predict_from_file(IN_FILE, text_col=TEXT_COL, out_csv=OUT_FILE)\n",
    "# display(file_out.head(10))\n",
    "\n",
    "# %% 5) (Optional) Quick metrics if ground truth exists (Score/Rating → label)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def derive_label_from_rating(s: pd.Series) -> pd.Series:\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s.apply(lambda r: \"positive\" if r >= 4 else (\"negative\" if r <= 2 else \"neutral\"))\n",
    "\n",
    "# After running the file prediction above, if the file had 'Score' or 'Rating':\n",
    "# gt_col = \"Score\"   # or \"Rating\"\n",
    "# if gt_col in file_out.columns:\n",
    "#     y_true = derive_label_from_rating(file_out[gt_col])\n",
    "#     y_pred = file_out[\"sentiment\"]\n",
    "#     print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db0952-ebba-47ae-92ff-136d950c5aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
