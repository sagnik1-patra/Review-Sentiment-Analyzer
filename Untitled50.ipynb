{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9c1312-a9a6-40d9-817d-f44a33290bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\Users\\NXTWAVE\\Downloads\\Review Sentiment Analyzer\\predict_reviews.py\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Tuple, Optional\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Reuse the same OUT_DIR used when training\n",
    "OUT_DIR = Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Review Sentiment Analyzer\")\n",
    "MODEL_PATH = OUT_DIR / 'model_sentiment.pkl'\n",
    "\n",
    "# Fallback rule-based utils (copy from training notebook)\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def rule_score(text: str) -> float:\n",
    "    vs = SentimentIntensityAnalyzer()\n",
    "    return float(vs.polarity_scores(text).get('compound', 0.0))\n",
    "\n",
    "\n",
    "def score_to_label(score: float, pos: float=0.2, neg: float=-0.2) -> str:\n",
    "    return 'positive' if score>=pos else ('negative' if score<=neg else 'neutral')\n",
    "\n",
    "\n",
    "def predict_one(text: str) -> Tuple[str, float]:\n",
    "    \"\"\"Predict a single review. Returns (label, confidence/score).\"\"\"\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return \"\", 0.0\n",
    "    try:\n",
    "        pipe = joblib.load(MODEL_PATH)\n",
    "        lab = pipe.predict([text])[0]\n",
    "        try:\n",
    "            proba = pipe.predict_proba([text])\n",
    "            conf = float(np.max(proba))\n",
    "        except Exception:\n",
    "            conf = 0.0\n",
    "        return lab, conf\n",
    "    except Exception:\n",
    "        # fallback (no model): VADER\n",
    "        comp = rule_score(text)\n",
    "        return score_to_label(comp), float(abs(comp))\n",
    "\n",
    "\n",
    "def predict_many(texts: Iterable[str]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for t in texts:\n",
    "        lab, conf = predict_one(t)\n",
    "        rows.append({\"text\": t, \"sentiment\": lab, \"confidence\": conf})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def predict_from_file(input_path: Path, text_col: str = 'reviewText', out_csv: Optional[Path] = None) -> pd.DataFrame:\n",
    "    \"\"\"Predict for each row in a CSV/JSON and write a predictions CSV.\"\"\"\n",
    "    if not input_path.exists():\n",
    "        raise FileNotFoundError(input_path)\n",
    "    if input_path.suffix.lower() == '.json':\n",
    "        df_in = pd.read_json(input_path, lines=True)\n",
    "    else:\n",
    "        df_in = pd.read_csv(input_path)\n",
    "\n",
    "    if text_col not in df_in.columns:\n",
    "        for cand in ['Text','text','review','content','reviewText']:\n",
    "            if cand in df_in.columns:\n",
    "                text_col = cand\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"Text column '{text_col}' not found. Available: {df_in.columns.tolist()}\")\n",
    "\n",
    "    preds = predict_many(df_in[text_col].astype(str).fillna(\"\").tolist())\n",
    "    out = pd.concat([df_in.reset_index(drop=True), preds[['sentiment','confidence']]], axis=1)\n",
    "\n",
    "    if out_csv is None:\n",
    "        out_csv = OUT_DIR / 'predictions.csv'\n",
    "    out.to_csv(out_csv, index=False)\n",
    "    print(f\"[OK] Wrote predictions → {out_csv}\")\n",
    "    return out\n",
    "\n",
    "# %% [markdown]\n",
    "# ### A) Single / Batch prediction in Notebook\n",
    "\n",
    "# %%\n",
    "TEST_REVIEWS = [\n",
    "    \"The camera quality is amazing but the battery dies too fast.\",\n",
    "    \"Worst purchase ever. Completely stopped working in a week.\",\n",
    "    \"Packaging was okay. Works as expected.\",\n",
    "    \"Love the sound quality and the build! Totally worth it.\",\n",
    "]\n",
    "res_df = predict_many(TEST_REVIEWS)\n",
    "res_df\n",
    "\n",
    "# %% [markdown]\n",
    "# ### B) Predict from a file and save results\n",
    "\n",
    "# %%\n",
    "# Example (uncomment and edit the text column name):\n",
    "# file_out = predict_from_file(\n",
    "#     input_path=Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Review Sentiment Analyzer\\archive\\Reviews.csv\"),\n",
    "#     text_col='Text',\n",
    "#     out_csv=OUT_DIR / 'predictions_from_reviews.csv'\n",
    "# )\n",
    "# display(file_out.head(10))\n",
    "\n",
    "# %% [markdown]\n",
    "# ### C) Optional: Quick metrics if ground truth available\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def derive_label_from_rating(s: pd.Series) -> pd.Series:\n",
    "    s = pd.to_numeric(s, errors='coerce')\n",
    "    return s.apply(lambda r: 'positive' if r>=4 else ('negative' if r<=2 else 'neutral'))\n",
    "\n",
    "# Example (uncomment after running section B above):\n",
    "# gt_col = 'Score'  # or 'Rating'\n",
    "# if gt_col in file_out.columns:\n",
    "#     y_true = derive_label_from_rating(file_out[gt_col])\n",
    "#     y_pred = file_out['sentiment']\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "\n",
    "# %% [markdown]\n",
    "# ---\n",
    "# ## Standalone Script — `predict_reviews.py`\n",
    "# Save the following as `predict_reviews.py` and run from PowerShell.\n",
    "# Usage examples:\n",
    "# ```powershell\n",
    "# # Predict a single text\n",
    "# python predict_reviews.py --text \"Battery life is poor but display is gorgeous\"\n",
    "#\n",
    "# # Predict for a CSV (text column named 'Text') and write predictions CSV\n",
    "# python predict_reviews.py --file \"C:\\\\Users\\\\NXTWAVE\\\\Downloads\\\\Review Sentiment Analyzer\\\\archive\\\\Reviews.csv\" --text-col Text --out \"C:\\\\Users\\\\NXTWAVE\\\\Downloads\\\\Review Sentiment Analyzer\\\\predictions_from_reviews.csv\"\n",
    "# ```\n",
    "\n",
    "# %%\n",
    "PREDICT_SCRIPT = r\"\"\"\n",
    "#!/usr/bin/env python3\n",
    "import argparse, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "OUT_DIR = Path(r\"C:\\Users\\NXTWAVE\\Downloads\\Review Sentiment Analyzer\")\n",
    "MODEL_PATH = OUT_DIR / 'model_sentiment.pkl'\n",
    "\n",
    "def rule_score(text: str) -> float:\n",
    "    vs = SentimentIntensityAnalyzer()\n",
    "    return float(vs.polarity_scores(text).get('compound', 0.0))\n",
    "\n",
    "def score_to_label(score: float, pos=0.2, neg=-0.2) -> str:\n",
    "    return 'positive' if score>=pos else ('negative' if score<=neg else 'neutral')\n",
    "\n",
    "def predict_one(text: str):\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        return \"\", 0.0\n",
    "    try:\n",
    "        pipe = joblib.load(MODEL_PATH)\n",
    "        lab = pipe.predict([text])[0]\n",
    "        try:\n",
    "            proba = pipe.predict_proba([text])\n",
    "            conf = float(np.max(proba))\n",
    "        except Exception:\n",
    "            conf = 0.0\n",
    "        return lab, conf\n",
    "    except Exception:\n",
    "        comp = rule_score(text)\n",
    "        return score_to_label(comp), float(abs(comp))\n",
    "\n",
    "def predict_file(file_path: Path, text_col: str, out_path: Path):\n",
    "    if file_path.suffix.lower() == '.json':\n",
    "        df_in = pd.read_json(file_path, lines=True)\n",
    "    else:\n",
    "        df_in = pd.read_csv(file_path)\n",
    "    if text_col not in df_in.columns:\n",
    "        raise SystemExit(f\"Column '{text_col}' not in file. Available: {df_in.columns.tolist()}\")\n",
    "    rows = []\n",
    "    for t in df_in[text_col].astype(str).fillna(\"\"):\n",
    "        lab, conf = predict_one(t)\n",
    "        rows.append((lab, conf))\n",
    "    df_in['sentiment'] = [r[0] for r in rows]\n",
    "    df_in['confidence'] = [r[1] for r in rows]\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_in.to_csv(out_path, index=False)\n",
    "    print(f\"[OK] Wrote predictions → {out_path}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument('--text', type=str, help='Single review text to predict')\n",
    "    ap.add_argument('--file', type=str, help='CSV/JSON path for batch prediction')\n",
    "    ap.add_argument('--text-col', type=str, default='reviewText', help='Text column name in the file')\n",
    "    ap.add_argument('--out', type=str, default=str(OUT_DIR / 'predictions.csv'))\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    if args.text:\n",
    "        lab, conf = predict_one(args.text)\n",
    "        print(json.dumps({'text': args.text, 'sentiment': lab, 'confidence': conf}, ensure_ascii=False))\n",
    "    elif args.file:\n",
    "        predict_file(Path(args.file), args.text_col, Path(args.out))\n",
    "    else:\n",
    "        ap.print_help()\n",
    "\"\"\"\n",
    "\n",
    "# Write the script to disk next to your OUT_DIR for convenience\n",
    "with open(OUT_DIR / 'predict_reviews.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(PREDICT_SCRIPT)\n",
    "print(\"Wrote:\", OUT_DIR / 'predict_reviews.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa9746-9210-4763-ba49-ac335b2ebb21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
